{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e875bcd-caf7-41fa-b11d-15306e8063ba",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791a8f65-1665-43e8-b646-3788b4c6d18a",
   "metadata": {},
   "source": [
    "The objective of this project is to perform sentiment analysis on movie reviews using an LSTM-based model. We'll classify reviews as positive or negative based on their text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c98fed3-9cf6-4fe4-91e7-0b050c0aa088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.65.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d33c11-2097-4762-9883-8a433f648185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.9.6)\n",
      "Requirement already satisfied: absl-py in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (8.0.4)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: immutabledict in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (4.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.24.3)\n",
      "Requirement already satisfied: promise in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (4.25.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (11.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.31.0)\n",
      "Requirement already satisfied: simple-parsing in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.1.6)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.16.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.4.0)\n",
      "Requirement already satisfied: toml in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (4.65.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.14.1)\n",
      "Requirement already satisfied: etils[enp,epath,epy,etree]>=1.9.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.10.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\anaconda3\\lib\\site-packages (from etils[enp,epath,epy,etree]>=1.9.1->tensorflow-datasets) (2023.4.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\dell\\anaconda3\\lib\\site-packages (from etils[enp,epath,epy,etree]>=1.9.1->tensorflow-datasets) (6.4.5)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\dell\\anaconda3\\lib\\site-packages (from etils[enp,epath,epy,etree]>=1.9.1->tensorflow-datasets) (4.11.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\dell\\anaconda3\\lib\\site-packages (from etils[enp,epath,epy,etree]>=1.9.1->tensorflow-datasets) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from click->tensorflow-datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\anaconda3\\lib\\site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5529e4d-80ce-467c-82e5-a2a4c76d4e37",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b7e5c2-8560-4c80-ad67-fece7e64cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc06ec-2a5e-4a6b-859e-cad40b15780b",
   "metadata": {},
   "source": [
    "# Load the IMDb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40012f06-e20d-47ec-9ae8-e88c8355b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDb dataset\n",
    "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)\n",
    "train_data, test_data = imdb['train'], imdb['test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad351a-5414-4056-91cb-cba587eeb637",
   "metadata": {},
   "source": [
    "# Convert Dataset to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ea790e-6146-4e42-abec-b23187f23d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was an absolutely terrible movie. Don't b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been known to fall asleep during films,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mann photographs the Alberta Rocky Mountains i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the kind of film for a snowy Sunday af...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As others have mentioned, all the women that g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Label\n",
       "0  This was an absolutely terrible movie. Don't b...      0\n",
       "1  I have been known to fall asleep during films,...      0\n",
       "2  Mann photographs the Alberta Rocky Mountains i...      0\n",
       "3  This is the kind of film for a snowy Sunday af...      1\n",
       "4  As others have mentioned, all the women that g...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow dataset ko list mein convert karo\n",
    "train_examples = [(review.numpy().decode('utf-8'), label.numpy()) for review, label in train_data.take(100)]  # Yahan hum 100 samples le rahe hain\n",
    "\n",
    "# Pandas DataFrame banao\n",
    "df_train = pd.DataFrame(train_examples, columns=['Review', 'Label'])\n",
    "\n",
    "# DataFrame ke pehle kuch rows dikhao\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d387deec-cebf-4868-8675-236ef8efa9af",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51eb6783-88da-45e9-aac4-7c33b7ea7dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# Clean the text: remove stopwords, non-alphabetic characters, etc.\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters (punctuation)\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove multiple spaces\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n",
    "    return text\n",
    "\n",
    "# Process training data\n",
    "train_sentences = []\n",
    "train_labels = []\n",
    "for s, l in train_data:\n",
    "    train_sentences.append(clean_text(str(s.numpy())))\n",
    "    train_labels.append(int(l.numpy()))\n",
    "\n",
    "# Process testing data\n",
    "test_sentences = []\n",
    "test_labels = []\n",
    "for s, l in test_data:\n",
    "    test_sentences.append(clean_text(str(s.numpy())))\n",
    "    test_labels.append(int(l.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf3b84-d5b2-49c1-997a-f8b157648c22",
   "metadata": {},
   "source": [
    "# Tokenization and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65fed235-1e8f-45dd-972f-6165df31d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters of the model\n",
    "\n",
    "vocab_size = 3000  # Choose based on statistics\n",
    "oov_tok = ''\n",
    "embedding_dim = 100\n",
    "max_length = 200  # Choose based on statistics, for example 150 to 200\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "\n",
    "# Tokenize sentences\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert train dataset to sequence and pad sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, padding='padding_type', maxlen=max_length)\n",
    "\n",
    "# Convert Test dataset to sequence and pad sequences\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, padding='padding_type', maxlen=max_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6309e-569c-4dcc-ab0a-2087d7af2bad",
   "metadata": {},
   "source": [
    "# Build the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc673cb7-4fa8-4812-a62f-64e68f50284f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">300,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">84,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │       \u001b[38;5;34m300,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m84,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m3,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m25\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">387,601</span> (1.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m387,601\u001b[0m (1.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">387,601</span> (1.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m387,601\u001b[0m (1.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model initialization\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(max_length,)),\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d5595-4add-47cf-81c6-20122d8a80d0",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34371e6b-2d1d-42ea-b13b-654d8e901e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 84ms/step - accuracy: 0.7131 - loss: 0.5479 - val_accuracy: 0.8544 - val_loss: 0.3736\n",
      "Epoch 2/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 119ms/step - accuracy: 0.8682 - loss: 0.3295 - val_accuracy: 0.8620 - val_loss: 0.3288\n",
      "Epoch 3/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 121ms/step - accuracy: 0.8944 - loss: 0.2703 - val_accuracy: 0.8576 - val_loss: 0.3586\n",
      "Epoch 4/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 112ms/step - accuracy: 0.9098 - loss: 0.2363 - val_accuracy: 0.8728 - val_loss: 0.3157\n",
      "Epoch 5/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 114ms/step - accuracy: 0.9170 - loss: 0.2179 - val_accuracy: 0.8740 - val_loss: 0.3139\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to numpy arrays\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "num_epochs = 5\n",
    "history = model.fit(train_padded, train_labels,\n",
    "                    epochs=num_epochs, verbose=1,\n",
    "                    validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab387b-ccdf-4125-a210-9bcd0d3f6f2b",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7948f51-bedc-4449-a9dc-58eb93abdc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step\n",
      "Accuracy of prediction on test set:  0.86032\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "\n",
    "prediction = model.predict(test_padded)\n",
    "\n",
    "# Get labels based on probability: 1 if p >= 0.5 else 0\n",
    "pred_labels = [1 if i >= 0.5 else 0 for i in prediction]\n",
    "\n",
    "# Calculate accuracy\n",
    "print(\"Accuracy of prediction on test set: \", accuracy_score(test_labels, pred_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b49f97-cc9f-4698-9455-167e82b193c7",
   "metadata": {},
   "source": [
    "### sentiment analysis model using an LSTM architecture to classify IMDb movie reviews as positive or negative. The model with 86% accuracy can be further improved by tuning hyperparameters or employing advanced techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba12956-087d-4ff1-9445-d24dd0fc2447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
